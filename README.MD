# ä½¿ç”¨ Carla ç”Ÿæˆ YOLOv5 è¨“ç·´è³‡æ–™é›†å·¥å…· | Carla YOLOv5 Dataset Generator  

## å°ˆæ¡ˆç°¡ä»‹ | Project Description

æœ¬å°ˆæ¡ˆä½¿ç”¨ [CARLA Simulator](https://carla.org/) æ­é…è‡ªè¨‚æ„Ÿæ¸¬å™¨è…³æœ¬ï¼Œè‡ªå‹•ç”ŸæˆåŒå€‹å ´æ™¯ä¸åŒå¤©æ°£ä¸”å¯ç”¨æ–¼ YOLOv5 è¨“ç·´çš„è³‡æ–™é›†ã€‚  
This project uses the [CARLA Simulator](https://carla.org/) along with custom sensor scripts to automatically generate datasets for YOLOv5 training, with the same scene under different weather conditions.  

<img src="images/demo1.gif" alt="demo1" width=500/>

---

## é–‹å§‹ä½¿ç”¨ | Getting Started

æœ¬å°ˆæ¡ˆæä¾›å…©ç¨®é–‹å§‹ä½¿ç”¨çš„æ–¹å¼ï¼Œè«‹é¸æ“‡é©åˆæ‚¨çš„æ–¹æ³•ï¼š

### æ–¹å¼ä¸€ | Option 1  

- è«‹ä¾ç…§ **æ­¥é©Ÿä¸€** è‡³ **æ­¥é©Ÿä¸ƒ** çš„æŒ‡ç¤ºæ‰‹å‹•åŸ·è¡Œæ¯å€‹æ­¥é©Ÿï¼Œé€™æ¨£å¯ä»¥è®“æ‚¨æ›´äº†è§£æ¯å€‹æ­¥é©Ÿçš„éç¨‹èˆ‡æ“ä½œã€‚  
  Please follow the instructions from **Step 1** to **Step 7** and execute each step manually. This will help you better understand the process and operations involved in each step. 

### æ–¹å¼äºŒ | Option 2  

- ä½¿ç”¨ `shellscript/generate_in_screen.sh` è…³æœ¬ï¼ˆåƒè€ƒ `shellscript/example.txt`ï¼‰ï¼Œé€™å€‹è…³æœ¬æœƒè‡ªå‹•å®Œæˆ **æ­¥é©Ÿä¸€** å’Œ **æ­¥é©ŸäºŒ** çš„æ“ä½œã€‚ï¼Œè«‹è‡ªè¡ŒåŸ·è¡Œ **æ­¥é©Ÿä¸‰** è‡³ **æ­¥é©Ÿä¸ƒ** ã€‚  
  Use the `shellscript/generate_in_screen.sh` script (refer to `shellscript/example.txt`), which will automatically complete **Step 1** and **Step 2**. Please manually execute **Step 3** to **Step 7** afterward.  

  **è«‹æ³¨æ„ | Note**  
  - é€™é‚Šçš„ **æ­¥é©Ÿä¸€** æ˜¯ä½¿ç”¨ Docker ä¾†å•Ÿå‹• Carla Serverï¼Œè«‹ç¢ºä¿æ‚¨çš„ç’°å¢ƒå·²ç¶“æ­£ç¢ºé…ç½®å¥½ Dockerã€‚  
    In this method, **Step 1** uses Docker to launch the Carla Server. Please ensure that Docker is properly set up in your environment.   
  - åœ¨åŸ·è¡Œ **æ­¥é©ŸäºŒ** çš„è…³æœ¬æ™‚ï¼Œå¯èƒ½æœƒé‡åˆ°å®¢æˆ¶ç«¯é€£æ¥è‡³ Carla server è¶…æ™‚çš„å•é¡Œï¼Œé€™å±¬æ–¼æ­£å¸¸ç¾è±¡ï¼Œè«‹è€å¿ƒç­‰å¾…ï¼Œä¸è¦è‡ªè¡Œåœæ­¢ã€‚  
    While executing the script in **Step 2**, you may encounter timeout issues when the client connects to the Carla Server. This is expected behaviorâ€”please be patient and do not stop the script manually.
  
---
  
## æ­¥é©Ÿä¸€: å•Ÿå‹•Carla Server | Step 1: Launch Carla Server
- **æ³¨æ„äº‹é … | Note**  
  æœ¬å°ˆæ¡ˆæ˜¯ä½¿ç”¨ VNC é ç«¯é€£ç·šè‡³ç„¡é ­ä¼ºæœå™¨ï¼ˆheadless serverï¼‰ä¸Šæ“ä½œï¼Œä¸¦å•Ÿå‹• Carla Serverã€‚  
  This project is designed to run on a headless server via VNC remote connection, where the Carla Server is launched remotely.

  Carla Server å•Ÿå‹•èˆ‡æ“ä½œæ•™å­¸è«‹åƒè€ƒä»¥ä¸‹é€£çµ  
  For detailed instructions on launching Carla Server on a remote headless server, refer to the guide below

  ğŸ”— [ä½¿ç”¨ TightVNC Viewer é ç«¯é€£ç·š Ubuntu ç„¡é ­ä¼ºæœå™¨ä¸¦å•Ÿå‹• Carla](https://i-m-kj.blogspot.com/2024/12/windows-ubuntu-tightvnc-viewer-remote.html)

## æ­¥é©ŸäºŒï¼šç”¢ç”ŸåŸå§‹è³‡æ–™ | Step 2: Generate Raw Data

### `generate_raw_data.py`

- **ç”¨é€”èªªæ˜ | Purpose**  
  åˆ©ç”¨ Carla æ¨¡æ“¬å™¨å•Ÿå‹•ä¸€å°è»Šè¼›ï¼Œæ›è¼‰ä¸‰ç¨®æ„Ÿæ¸¬å™¨ï¼ˆRGB ç›¸æ©Ÿã€é›·é”ã€Instance Segmentation ç›¸æ©Ÿï¼‰ä»¥æ”¶é›†åŸå§‹è¨“ç·´è³‡æ–™ã€‚  
  This script uses the Carla simulator to spawn a vehicle and attach three sensors: an RGB camera, a radar, and an instance segmentation camera, to collect raw data for training.  

- **åƒæ•¸ | Parameters**
  #### `--rawdata-path`
  **æè¿°**: å­˜æ”¾åŸå§‹è³‡æ–™çš„è·¯å¾‘ã€‚  
  **Description**: Path to store the raw data.  
  **Example**: `--rawdata-path /path/to/rawdata`

  #### `-w`
  **æè¿°**: è¡Œäººæ•¸é‡ã€‚  
  **Description**: Number of pedestrians.  
  **Example**: `-w 10`  

  #### `-n`
  **æè¿°**: è»Šå­æ•¸é‡ã€‚  
  **Description**: Number of cars.  
  **Example**: `-n 20`  

  #### `--radar`
  **æè¿°**: é›·é”çš„åƒæ•¸ã€‚  
  **Description**: Parameters for the radar.  
  **Example**: `--radar 90.0 50000 80 0 25`  

  #### `--interval`
  **æè¿°**: æ”¶é›†è³‡æ–™çš„é »ç‡ï¼ˆç§’ï¼‰ã€‚  
  **Description**: Frequency (in seconds) for collecting data.  
  **Example**: `--interval 60`  

  #### `--projectionflag`
  **æè¿°**: åŠæ™‚é¡¯ç¤ºé›·é”é»æŠ•å½±è‡³ç›¸æ©Ÿçš„é–‹é—œã€‚  
  **Description**: Switch to display radar points projected onto the camera in real-time.  
  **Example**: `--projectionflag True`  

  #### `--port`
  **æè¿°**: CARLA server çš„ç«¯å£ã€‚  
  **Description**: Port for the CARLA server.  
  **Example**: `--port 3000`  

  #### `--res`
  **æè¿°**: è¦–çª—è§£æåº¦ã€‚  
  **Description**: Resolution of the window.  
  **Example**: `--res 1920x1080`  

  ---
  æœ‰èˆˆè¶£çš„æœ‹å‹å¯ä»¥åƒè€ƒ [CARLA å®˜æ–¹æ–‡æª”](https://carla.readthedocs.io/en/latest/)  

  If you're interested, you can refer to the [CARLA Official Documentation](https://carla.readthedocs.io/en/latest/).  


---

## æ­¥é©Ÿä¸‰ï¼šè™•ç†é›·é”èˆ‡ç›¸æ©Ÿè³‡æ–™ | Step 3: Process Radar and Camera Data

æœ¬å°ˆæ¡ˆæ˜¯ç‚ºäº† **ç›¸æ©Ÿèˆ‡é›·é”èåˆï¼ˆFusion: Camera + Radarï¼‰** è€Œè¨­è¨ˆï¼Œå› æ­¤æœƒä½¿ç”¨é›·é”é»è³‡æ–™ï¼Œä¸¦ç”¢ç”Ÿä¸‹åˆ—å¤šé€šé“æ ¼å¼çš„å½±åƒï¼š
This project is designed for **sensor fusion (camera + radar)**. It utilizes radar point data and generates multi-channel image formats as follows:

- `(R, G, B)`
- `(R, G, B, radar_detect)`
- `(R, G, B, radar_detect, radar_depth)`
- `(R, G, B, radar_detect, radar_depth, radar_pos_velocity, radar_neg_velocity)`

---

### `rawdata_to_cleandata.py`  

- **ç”¨é€”èªªæ˜ | Purpose**  

  éæ¿¾æ‰ä¸åœ¨ç‰©ä»¶ä¸Šçš„é›·é”é»ã€‚
  çµåˆ instance segmentation camera çš„è³‡è¨Šï¼Œç‚ºå½±åƒåŠ ä¸Šæ¨™è¨»ã€‚
  æœ€çµ‚åœ¨ `cleandata/` è³‡æ–™å¤¾ä¸‹ç”¢ç”Ÿï¼š
    - `camera/`, `radar/`
    - `labels-3/`, `labels-4/`, `labels-5/`, `labels-7/`
    - ä¸¦æ–¼ `check_data_bboxNradar/bboxNradar/` ä¸­ç”¢ç”Ÿå°æ‡‰å¯è¦–åŒ–çµæœã€‚

  Filters out radar points not located on objects.
  Uses the instance segmentation camera to label the images.
  Produces output in the `cleandata/` directory:
    - `camera/`, `radar/`
    - `labels-3/`, `labels-4/`, `labels-5/`, `labels-7/`
    - Visualization results stored under `check_data_bboxNradar/bboxNradar/`

- **åƒæ•¸ | Parameters**  
  å¯ä½¿ç”¨ `--read-parent-dir` åƒæ•¸æŒ‡å®šè¦è®€å–çš„åŸå§‹è³‡æ–™å¤¾ä½ç½®ï¼Œé€é `--write-parent-dir` æŒ‡å®šè¼¸å‡ºçš„ç›®éŒ„ä½ç½®ï¼Œä¸¦å¯é€é `--check-parent-dir` æŒ‡å®šè¼¸å‡ºBboximgçš„ç›®éŒ„ä½ç½®ã€‚
  Use the `--read-parent-dir` argument to specify the source directory, the `--write-parent-dir` argument to specify the target output directory, and the `--check-parent-dir` argument to specify the output directory for Bbox images.

---

### è‹¥åªä½¿ç”¨ RGB åœ–åƒ | If Using RGB-Only Images  

è‹¥ä½ åªéœ€è¦ä½¿ç”¨ RGB åœ–åƒä¾†è¨“ç·´æ¨¡å‹ï¼Œå¯ä¿®æ”¹ç¨‹å¼ç¢¼ï¼Œä¸¦åœ¨ `config/file.py` ä¸­è¨­å®š  
If you only want to use RGB images for object detection, you can modify the code and set the following in `config/file.py`  

```python
CHANNELS = [3]
```

## æ­¥é©Ÿå››ï¼šç”Ÿæˆ YOLOv5 è¨“ç·´è³‡æ–™ | Step 4: Generate YOLOv5 Training Data

### `cleandata_to_sourcedata.py`
  
- **ç”¨é€”èªªæ˜ | Purpose**  
  æ­¤è…³æœ¬æœƒä½¿ç”¨ `cleandata/` è³‡æ–™å¤¾ä¸­çš„ `camera/` èˆ‡ `radar/`ï¼Œç”Ÿæˆ YOLOv5 æ‰€éœ€çš„è¼¸å…¥è¨“ç·´è³‡æ–™ã€‚è¼¸å‡ºæœƒåˆ†åˆ¥å­˜æ”¾åœ¨ `sourcedata/` åº•ä¸‹çš„ `3-channel/`ã€`4-channel/`ã€`5-channel/` ä»¥åŠ `7-channel/` è³‡æ–™å¤¾ä¸­ã€‚æ­¤å¤–ï¼Œæ­¥é©Ÿä¸‰æ‰€ç”¢ç”Ÿçš„ `labels` ä¹Ÿæœƒä¸€ä½µè¢«ç§»å‹•è‡³é€™äº›è³‡æ–™å¤¾ã€‚  
  This script uses the `camera/` and `radar/` folders under `cleandata/` to generate input training data for YOLOv5. The output will be saved under `sourcedata/` in the subdirectories: `3-channel/`, `4-channel/`, `5-channel/`, and `7-channel/`. The `labels` generated from Step 3 will also be moved accordingly.

  âš ï¸ **æ³¨æ„ï¼šè‹¥ä½¿ç”¨ 4-channelã€5-channel æˆ– 7-channelï¼Œéœ€è¦ä¿®æ”¹ YOLOv5 çš„æ¨¡å‹çµæ§‹ä»¥æ”¯æ´é 3-channel çš„è¼¸å…¥ã€‚**  
  âš ï¸ **Note: If you plan to use 4-channel, 5-channel, or 7-channel data, you must modify the YOLOv5 model to support non-3-channel inputs.**

- **åƒæ•¸ | Parameters**  
  å¯ä½¿ç”¨ `--read-parent-dir` åƒæ•¸æŒ‡å®šè¦è®€å–çš„åŸå§‹è³‡æ–™å¤¾ä½ç½®ï¼Œä¸¦å¯é€é `--write-parent-dir` æŒ‡å®šè¼¸å‡ºçš„ç›®éŒ„ä½ç½®ã€‚
  Use the `--read-parent-dir` argument to specify the source directory, and the `--write-parent-dir` argument to specify the target output directory. 


## æ­¥é©Ÿäº”ï¼šå»ºç«‹è³‡æ–™é›†æ ¼å¼ | Step 4: Create Dataset Format  

### `convert_to_dataset.py`  

- **ç”¨é€”èªªæ˜ | Purpose**  
  æ­¤è…³æœ¬æœƒä½¿ç”¨ Linux çš„ symbolic link æ©Ÿåˆ¶ï¼Œä¸”ä¾ç…§æ‚¨æŒ‡å®šçš„æ ¼å¼ä¾†å‰µå»ºå‡ºè¨“ç·´ç”¨çš„è³‡æ–™é›†ã€‚  
  This script uses Linux's symbolic link mechanism to create training datasets based on the specified format.  

- **åƒæ•¸ | Parameters**  
  å¯ä½¿ç”¨ `--format` åƒæ•¸æŒ‡å®šè¼¸å‡ºæ ¼å¼ç‚º `"yolo"` æˆ– `"voc"`ï¼Œä¸¦å¯é€é `--n` åƒæ•¸è¨­å®šè³‡æ–™é›†çš„ç¸½æ•¸é‡å¤§å°ã€‚
  Use the `--format` argument to specify the output format as `"yolo"` or `"voc"`, and the `--n` argument to define the total number of data samples.
  
## æ­¥é©Ÿå…­:é–‹å§‹è¨“ç·´ | Step 5: Start Training  

è«‹å…ˆ Clone YOLOv5 åŸå§‹ç¢¼ï¼Œæ¥è‘—å³å¯ä½¿ç”¨æ­¥é©Ÿäº”ç”¢ç”Ÿçš„è¨“ç·´é›†é€²è¡Œè¨“ç·´ã€‚  
First, clone the official YOLOv5 repository, then you can start training using the dataset generated in Step 5.

```bash
git clone https://github.com/ultralytics/yolov5

cd yolov5

pip install -r requirements.txt
```

ç„¶å¾Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤é–‹å§‹è¨“ç·´  
Then, use the following command to start training  

```bash
# ä½¿ç”¨ 3 é€šé“åœ–åƒé€²è¡Œå¾é ­è¨“ç·´ | Train From Scratch Using 3-Channel Images
python train.py --weights "" --data /path/to/YOLOcarla-3/data.yaml --cfg yolov5n.yaml --batch-size 64 --epochs 100 
```  

## æ­¥é©Ÿä¸ƒ:æ¨¡å‹æ¨è«– | Step 7: Inference  

ç•¶æ¨¡å‹è¨“ç·´å®Œæˆå¾Œï¼Œå¯ä½¿ç”¨ä¸‹åˆ—æŒ‡ä»¤å°å½±åƒé€²è¡Œæ¨è«–èˆ‡åµæ¸¬  
Once training is complete, you can run inference on your images using the following command  

```bash
python detect.py --weights /path/to/weights/best.pt --source /path/to/YOLOcarla-3/images/test/ 
```  

<img src="images/demo2.jpg" alt="demo2" width=600/>
<img src="images/demo3.jpg" alt="demo3" width=600/>

## ç¡¬é«”è¨­å‚™è³‡è¨Š | Server Specifications

æœ¬å°ˆæ¡ˆæ–¼ä»¥ä¸‹ä¼ºæœå™¨ç’°å¢ƒæ¸¬è©¦é€šéï¼š  
This project has been tested on the following server environment:

- ä½œæ¥­ç³»çµ± / OSï¼šUbuntu 20.04.6
- è™•ç†å™¨ / CPUï¼š12th Gen Intel(R) Core(TM) i9-12900
- è¨˜æ†¶é«” / RAMï¼š62GB
- é¡¯ç¤ºå¡ / GPUï¼šNVIDIA GeForce RTX 3090 (24GB)
- Python ç‰ˆæœ¬ / Python Versionï¼š3.7.16
- Docker ç‰ˆæœ¬ / Docker Versionï¼š26.0.2
- Carla Simulatorï¼š0.9.15
